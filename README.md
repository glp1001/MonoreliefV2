<div align="center">
<h1>MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery
</h1>

[**Yu-Wei Zhang**]<sup>1*&dagger;</sup> · [**Tongju Han**]<sup>1</sup> · [**Lipeng Gao**]<sup>1</sup>
<br>
[**Mingqiang Wei**]<sup>2</sup> · [**Hui Liu**]<sup>3</sup> · [**Changbao Li**]<sup>1</sup> · [**Caiming Zhang**]<sup>4</sup>

<sup>1</sup>QLU&emsp;&emsp;&emsp;<sup>2</sup>NUAA;<sup>3</sup>SDUFE;<sup>4</sup>SDU
<br>
&dagger;project lead&emsp;*corresponding author

This work presents Depth Anything V2. It significantly outperforms [V1](https://github.com/LiheYoung/Depth-Anything) in fine-grained details and robustness. Compared with SD-based models, it enjoys faster inference speed, fewer parameters, and higher depth accuracy.

<div style="width: 600px; margin: auto;">
  <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 0px;">
    <div><img src="github/g1.jpg" alt="Image 1" width="150"></div>
    <div><img src="github/g1_d.png" alt="Image 2" width="150"></div>
    <div><img src="github/g1_n.jpg" alt="Image 3" width="150"></div>
  </div>
</div>


## News
- **2025-01-22:** [Video Depth Anything](https://videodepthanything.github.io) has been released. It generates consistent depth maps for super-long videos (e.g., over 5 minutes).
